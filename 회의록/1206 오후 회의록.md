# 12/06 오후 회의록

## 논의 사항

### 1. PySpark에서 csv 파일을 읽어오지 못하는 문제
- csv 파일 읽어올때 변수 설정, header 이름을 변경하여 해결

### 2. 분석 방향과 최종 결과 보여주는 방향의 차이 
#### 윤철님이 진행하셨던 분석 방식
- 정책 단어 중 평균적으로 많이 나오는 단어와 적게 나오는 단어가 있음.
- 중간값을 정해서, 해당 중간값 보다 많은 양의 단어가 나온 월 중 top 5개를 정해서 해당 월에만 정책이 발표되었다고 가정.
- 따라서 최대 15개의 월에만 정책이 맵핑됨.

#### 동준님이 작성해오신 기사를 가져오는 방식
- 사용자가 기간을 입력하면 무조건 6개월 전의 기사 중 가장 의미있는 기사 top n개를 가져온다.

#### => 6개월 전 기사를 가져왔을 때 정책이 none이면 가져올 기사가 없는 문제가 발생 

#### 현재 나온 해결책
- 정책이 매핑된 월기준, 수개월간(최대 12개월) 정책이 집값 변동에 미치는 영향 수치를 구함 -> none 값을 찾을 경우 해당 달을 pass. 대신에 정책이 있는 달 중 영향을 가장 많이 미치는 달의 정책 기사를 찾아 반환
- 시간 부족으로 분석 방법을 변경하지 못했을 경우 -> 그냥 사용자 입력한 월 기준 가장 최신 달의 정책 기사를 가져옴

### 3. 기사 가져오는 api 사용 진행 현황
- fast api 사용해서 기간 입력시 6개월 전 기사를 가져오게 작동.
- 실제 사용예시 보여주고 싶으면 ipynb 코드 사용해서 기사 긁어오고, 기사 url로 기사 원본으로 연결될 수 있음.

### 4. 추가로 해야할 일
1. 각자 코드 완성
2. 발표 대본을 위한 샘플 보고서 작성
3. 각자 맡은 부분 ppt 만들기  

~ 토요일(12/7) 저녁까지 마무리.

